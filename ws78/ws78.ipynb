{"cells": [{"cell_type": "code", "execution_count": 26, "id": "22ee50af", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 89:===========================================>              (3 + 1) / 4]\r"}, {"name": "stdout", "output_type": "stream", "text": "+------------+--------------------+\n|pulocationid|avg(passenger_count)|\n+------------+--------------------+\n|       201.0|  1.2727272727272727|\n|       180.0|  1.1441441441441442|\n|       155.0|  1.3506493506493507|\n|       107.0|  1.5935749372598926|\n|        29.0|  1.7891156462585034|\n|        47.0|  1.3846153846153846|\n|       178.0|   1.305263157894737|\n|       237.0|  1.5436682073120067|\n|       177.0|  1.3214285714285714|\n|       159.0|  1.5083798882681565|\n|         1.0|  1.6043478260869566|\n|       250.0|  1.5190839694656488|\n|        94.0|  1.2758620689655173|\n|       114.0|  1.6171467254820606|\n|       149.0|  1.6303030303030304|\n|       137.0|  1.5607611359377251|\n|       245.0|                 1.2|\n|       122.0|  1.4328358208955223|\n|       197.0|  1.4158878504672898|\n|       165.0|  1.4825174825174825|\n+------------+--------------------+\nonly showing top 20 rows\n\nCPU times: user 7.66 ms, sys: 7.96 ms, total: 15.6 ms\nWall time: 27.8 s\n"}, {"name": "stderr", "output_type": "stream", "text": "\r                                                                                \r"}], "source": "%%time\nfrom pyspark.sql import SparkSession\n# Create a SparkSession instance (an entry point to all Spark functions)\nspark = SparkSession.builder.appName(\"MYAPP\").getOrCreate()\n# Read a file in CSV format into Spark DataFrame\ndf = spark.read.csv('gs://dataproc-staging-us-east1-484410736875-hru3bcdb/data/data_sample5.csv', header=True, inferSchema=True)\n# Groups the DataFrame using the specified columns and returns the average of the values in a group\ndf.groupBy('pulocationid').avg('passenger_count').show()"}, {"cell_type": "code", "execution_count": null, "id": "c5c21442", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}