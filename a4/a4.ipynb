{"cells": [{"cell_type": "code", "execution_count": 29, "id": "f6eba267", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------------+------------+------------+------------+\n|passenger_count|pulocationid|dolocationid|total_amount|\n+---------------+------------+------------+------------+\n|            1.0|       151.0|       239.0|        9.95|\n|            1.0|       239.0|       246.0|        16.3|\n|            3.0|       236.0|       236.0|         5.8|\n|            5.0|       193.0|       193.0|        7.55|\n|            5.0|       193.0|       193.0|       55.55|\n|            5.0|       193.0|       193.0|       13.31|\n|            5.0|       193.0|       193.0|       55.55|\n|            1.0|       163.0|       229.0|        9.05|\n|            1.0|       229.0|         7.0|        18.5|\n|            2.0|       141.0|       234.0|        13.0|\n+---------------+------------+------------+------------+\nonly showing top 10 rows\n\nroot\n |-- vendorid: string (nullable = true)\n |-- tpep_pickup_datetime: string (nullable = true)\n |-- tpep_dropoff_datetime: string (nullable = true)\n |-- passenger_count: double (nullable = true)\n |-- trip_distance: string (nullable = true)\n |-- ratecodeid: string (nullable = true)\n |-- store_and_fwd_flag: string (nullable = true)\n |-- pulocationid: double (nullable = true)\n |-- dolocationid: double (nullable = true)\n |-- payment_type: string (nullable = true)\n |-- fare_amount: string (nullable = true)\n |-- extra: string (nullable = true)\n |-- mta_tax: string (nullable = true)\n |-- tip_amount: string (nullable = true)\n |-- tolls_amount: string (nullable = true)\n |-- improvement_surcharge: string (nullable = true)\n |-- total_amount: double (nullable = true)\n |-- congestion_surcharge: string (nullable = true)\n\n"}], "source": "# show the first 10 entries\nfilePath = \"gs://dataproc-staging-us-east1-484410736875-hru3bcdb/2019-01-h1.csv\"\ndf = spark.read.option(\"delimiter\", \",\").option(\"header\", True).csv(filePath)\ndf.select(\"passenger_count\", \"pulocationid\", \"dolocationid\", \"total_amount\").show(10)\n\n# Convert to float\ndf = df.withColumn(\"passenger_count\",df.passenger_count.cast('double'))\ndf = df.withColumn(\"pulocationid\",df.pulocationid.cast('double'))\ndf = df.withColumn(\"dolocationid\",df.dolocationid.cast('double'))\ndf = df.withColumn(\"total_amount\",df.total_amount.cast('double'))\n\ndf.printSchema()"}, {"cell_type": "code", "execution_count": 30, "id": "c8678061", "metadata": {}, "outputs": [], "source": "# Create trainDF and testDF\ntrainDF, testDF = df.randomSplit([.8, .2], seed=42)\n# print(f\"\"\"There are {trainDF.count()} rows in the training set, and {testDF.count()} in the test set\"\"\")"}, {"cell_type": "code", "execution_count": 31, "id": "b54ccc9d", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "\r[Stage 51:>                                                         (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------------+------------+\n|         features|total_amount|\n+-----------------+------------+\n| [1.0,80.0,112.0]|         6.3|\n| [1.0,114.0,79.0]|       32.75|\n| [1.0,50.0,226.0]|        25.3|\n|  [1.0,249.0,4.0]|         9.8|\n|[1.0,158.0,158.0]|         5.8|\n| [1.0,246.0,68.0]|         7.8|\n|[1.0,164.0,224.0]|        10.8|\n|[1.0,226.0,129.0]|        55.3|\n|[1.0,142.0,260.0]|        17.3|\n|[1.0,141.0,133.0]|        40.0|\n+-----------------+------------+\nonly showing top 10 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "\r                                                                                \r"}], "source": "# Create a decision tree regressor to predict total_amount \n    # from the other three features.\n# Preparing features with transformer\nfrom pyspark.ml.feature import VectorAssembler\nvecAssembler = VectorAssembler(inputCols=[\"passenger_count\", \"pulocationid\", \"dolocationid\"], outputCol=\"features\")\nvecTrainDF = vecAssembler.transform(trainDF)\nvecTrainDF.select(\"features\", \"total_amount\").show(10)"}, {"cell_type": "code", "execution_count": 32, "id": "92d81b9a", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/04/17 00:11:48 WARN Instrumentation: [83a068f0] regParam is zero, which might cause numerical instability and overfitting.\n                                                                                \r"}], "source": "# Using estimators to build model\nfrom pyspark.ml.regression import LinearRegression\nlr = LinearRegression(featuresCol=\"features\", labelCol=\"total_amount\")\nlrModel = lr.fit(vecTrainDF)"}, {"cell_type": "code", "execution_count": 33, "id": "cf6b7d69", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "The formula for the linear regression is \nprice = -0.13*features + 20.25\n"}], "source": "# Apply parameters in transformer to generate predictions\nm = round(lrModel.coefficients[0], 2)\nb = round(lrModel.intercept, 2)\nprint(f\"\"\"The formula for the linear regression is \nprice = {m}*features + {b}\"\"\")"}, {"cell_type": "code", "execution_count": 34, "id": "e1504e01", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/04/17 00:13:36 WARN Instrumentation: [a590ddb6] regParam is zero, which might cause numerical instability and overfitting.\n[Stage 56:>                                                         (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---------------+------------+------------+------------------+\n|passenger_count|pulocationid|dolocationid|        prediction|\n+---------------+------------+------------+------------------+\n|            1.0|       223.0|       223.0|14.295507101430278|\n|            1.0|       234.0|       186.0|14.819666221870735|\n|            1.0|       158.0|       249.0|14.474684931784473|\n|            1.0|       140.0|       237.0|14.850869212545367|\n|            1.0|       148.0|        79.0|17.461753356595686|\n|            1.0|       233.0|       198.0|14.625122630225736|\n|            1.0|       158.0|       164.0| 15.92041896284379|\n|            4.0|       161.0|       229.0|14.466387913762233|\n|            1.0|       143.0|       262.0| 14.39697321224956|\n|            3.0|        37.0|        36.0|19.041095634239447|\n+---------------+------------+------------+------------------+\nonly showing top 10 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "\r                                                                                \r"}], "source": "# Creating a pipeline\nfrom pyspark.ml import Pipeline\npipeline = Pipeline(stages=[vecAssembler, lr])\npipelineModel = pipeline.fit(trainDF)\n\npredDF = pipelineModel.transform(testDF)\npredDF.select(\"passenger_count\", \"pulocationid\", \"dolocationid\", \"prediction\").show(10)"}, {"cell_type": "code", "execution_count": 35, "id": "3ea8ff2d", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 57:===========================================>              (3 + 1) / 4]\r"}, {"name": "stdout", "output_type": "stream", "text": "72.71737130085947\n"}, {"name": "stderr", "output_type": "stream", "text": "\r                                                                                \r"}], "source": "# Evaluating model\nfrom pyspark.ml.evaluation import RegressionEvaluator\nregressionEvaluator = RegressionEvaluator(\n    predictionCol=\"prediction\",\n    labelCol=\"total_amount\",\n    metricName=\"rmse\")\nrmse = regressionEvaluator.evaluate(predDF)\nprint(rmse)"}, {"cell_type": "code", "execution_count": 36, "id": "28881395", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Saving model\npipelinePath = \"/tmp/lr-pipeline-model\"\npipelineModel.write().overwrite().save(pipelinePath)"}, {"cell_type": "code", "execution_count": null, "id": "e2b55827", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}